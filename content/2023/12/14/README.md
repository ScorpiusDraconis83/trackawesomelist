# Awesome List Updates on Dec 14, 2023

2 awesome lists updated today.

[🏠 Home](/README.md) · [🔍 Search](https://www.trackawesomelist.com/search/) · [🔥 Feed](https://www.trackawesomelist.com/rss.xml) · [📮 Subscribe](https://trackawesomelist.us17.list-manage.com/subscribe?u=d2f0117aa829c83a63ec63c2f&id=36a103854c) · [❤️  Sponsor](https://github.com/sponsors/theowenyoung)



## [1. Awesome Azure Openai Llm](/content/kimtth/awesome-azure-openai-llm/README.md)

### **RAG Pipeline & Advanced RAG**

*   Demystifying Advanced RAG Pipelines: An LLM-powered advanced RAG pipeline built from scratch [git (⭐776)](https://github.com/pchunduri6/rag-demystified) \[19 Oct 2023]

### **Vector Database Comparison**

*   [Faiss](https://faiss.ai/): Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors. It is used as an alternative to a vector database in the development and library of algorithms for a vector database. It is developed by Facebook AI Research. [git (⭐30k)](https://github.com/facebookresearch/faiss) \[Feb 2017]

### **Semantic Kernel** / **Azure AI Search**

*   Microsoft LangChain Library supports C# and Python and offers several features, some of which are still in development and may be unclear on how to implement. However, it is simple, stable, and faster than Python-based open-source software. The features listed on the link include: [Semantic Kernel Feature Matrix](https://learn.microsoft.com/en-us/semantic-kernel/get-started/supported-languages) / doc:[ref](https://learn.microsoft.com/en-us/semantic-kernel) / blog:[ref](https://devblogs.microsoft.com/semantic-kernel/) / [git](https://aka.ms/sk/repo) \[Feb 2023]

### **LangChain features and related libraries** / DSPy optimizer

*   [LangChain Expression Language](https://python.langchain.com/docs/guides/expression_language/): A declarative way to easily compose chains together \[Aug 2023]
*   [OpenGPTs (⭐6.4k)](https://github.com/langchain-ai/opengpts): An open source effort to create a similar experience to OpenAI's GPTs \[Nov 2023]
*   [langflow (⭐24k)](https://github.com/logspace-ai/langflow): LangFlow is a UI for LangChain, designed with react-flow. \[Feb 2023]
*   [Flowise (⭐29k)](https://github.com/FlowiseAI/Flowise) Drag & drop UI to build your customized LLM flow \[Apr 2023]

### **Prompt Engineering** / **Prompt Template Language**

*   Power of Prompting

    *   [GPT-4 with Medprompt](https://arxiv.org/abs/2311.16452): GPT-4, using a method called Medprompt that combines several prompting strategies, has surpassed MedPaLM 2 on the MedQA dataset without the need for fine-tuning. [ref](https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/) \[28 Nov 2023]
    *   [promptbase (⭐5.3k)](https://github.com/microsoft/promptbase): Scripts demonstrating the Medprompt methodology \[Dec 2023]

### **Prompt Guide & Leaked prompts** / **Prompt Template Language**

*   [Prompts for Education (⭐1.5k)](https://github.com/microsoft/prompts-for-edu): Microsoft Prompts for Education \[Jul 2023]

### **RLHF (Reinforcement Learning from Human Feedback) & SFT (Supervised Fine-Tuning)** / **Llama Finetuning**

*   OpenAI Spinning Up in Deep RL!: An educational resource to help anyone learn deep reinforcement learning. [git (⭐9.9k)](https://github.com/openai/spinningup) \[Nov 2018]

### **Quantization Techniques** / **Llama Finetuning**

*   bitsandbytes: 8-bit optimizers [git (⭐5.9k)](https://github.com/TimDettmers/bitsandbytes) \[Oct 2021]

### **Other techniques and LLM patterns** / **Llama Finetuning**

*   [Mixture of experts models](https://mistral.ai/news/mixtral-of-experts/): Mixtral 8x7B: Sparse mixture of experts models (SMoE) [magnet](https://x.com/MistralAI/status/1706877320844509405?s=20) \[Dec 2023]
*   [Huggingface Mixture of Experts Explained](https://huggingface.co/blog/moe): Mixture of Experts, or MoEs for short \[Dec 2023]
*   [Simplifying Transformer Blocks](https://arxiv.org/abs/2311.01906): Simplifie Transformer. Removed several block components, including skip connections, projection/value matrices, sequential sub-blocks and normalisation layers without loss of training speed. \[3 Nov 2023]

### **Numbers LLM** / **GPT series release date**

*   [tiktoken (⭐12k)](https://github.com/openai/tiktoken): BPE tokeniser for use with OpenAI's models. Token counting. \[Dec 2022]
*   [What are tokens and how to count them?](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them): OpenAI Articles
*   [Byte-Pair Encoding (BPE)](https://arxiv.org/abs/1508.07909): P.2015. The most widely used tokenization algorithm for text today. BPE adds an end token to words, splits them into characters, and merges frequent byte pairs iteratively until a stop criterion. The final tokens form the vocabulary for new data encoding and decoding. \[31 Aug 2015] / [ref](https://towardsdatascience.com/byte-pair-encoding-subword-based-tokenization-algorithm-77828a70bee0) \[13 Aug 2021]

### **Trustworthy, Safe and Secure LLM** / **GPT series release date**

*   [NeMo Guardrails (⭐3.9k)](https://github.com/NVIDIA/NeMo-Guardrails): Building Trustworthy, Safe and Secure LLM Conversational Systems \[Apr 2023]
*   [Hallucination Leaderboard (⭐1.1k)](https://github.com/vectara/hallucination-leaderboard/): Evaluate how often an LLM introduces hallucinations when summarizing a document. \[Nov 2023]

### **Large Language Model Is: Abilities** / **GPT series release date**

*   Math soving optimized LLM [WizardMath](https://arxiv.org/abs/2308.09583): \[[cnt](https://scholar.google.com/scholar?hl=en\&as_sdt=0%2C5\&q=arxiv%3A+2308.09583)]: Developed by adapting Evol-Instruct and Reinforcement Learning techniques, these models excel in math-related instructions like GSM8k and MATH. [git (⭐9.2k)](https://github.com/nlpxucan/WizardLM) \[18 Aug 2023] / Math solving Plugin: [Wolfram alpha](https://www.wolfram.com/wolfram-plugin-chatgpt/)

### **Build an LLMs from scratch: picoGPT and lit-gpt** / **GPT series release date**

*   lit-gpt: Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. [git (⭐9.4k)](https://github.com/Lightning-AI/lit-gpt) \[Mar 2023]
*   [pix2code (⭐12k)](https://github.com/tonybeltramelli/pix2code): Generating Code from a Graphical User Interface Screenshot. Trained dataset as a pair of screenshots and simplified intermediate script for HTML, utilizing image embedding for CNN and text embedding for LSTM, encoder and decoder model. Early adoption of image-to-code. \[May 2017] -> [Screenshot to code (⭐16k)](https://github.com/emilwallner/Screenshot-to-code): Turning Design Mockups Into Code With Deep Learning \[Oct 2017] [ref](https://blog.floydhub.com/turning-design-mockups-into-code-with-deep-learning/)

### **LLM Materials for East Asian Languages** / Japanese

*   [ブレインパッド社員が投稿した Qiita 記事まとめ](https://blog.brainpad.co.jp/entry/2023/07/27/153055): ブレインパッド社員が投稿した Qiita 記事まとめ \[Jul 2023]
*   [New Era of Computing - ChatGPT がもたらした新時代](https://speakerdeck.com/dahatake/new-era-of-computing-chatgpt-gamotarasitaxin-shi-dai-3836814a-133a-4879-91e4-1c036b194718) \[May 2023]
*   [大規模言語モデルで変わる ML システム開発](https://speakerdeck.com/hirosatogamo/da-gui-mo-yan-yu-moderudebian-warumlsisutemukai-fa): ML system development that changes with large-scale language models \[Mar 2023]
*   [GPT-4 登場以降に出てきた ChatGPT/LLM に関する論文や技術の振り返り](https://blog.brainpad.co.jp/entry/2023/06/05/153034): Review of ChatGPT/LLM papers and technologies that have emerged since the advent of GPT-4 \[Jun 2023]
*   [LLM を制御するには何をするべきか？](https://blog.brainpad.co.jp/entry/2023/06/08/161643): How to control LLM \[Jun 2023]
*   [1. 生成 AI のマルチモーダルモデルでできること](https://blog.brainpad.co.jp/entry/2023/06/06/160003): What can be done with multimodal models of generative AI [2. 生成 AI のマルチモーダリティに関する技術調査](https://blog.brainpad.co.jp/entry/2023/10/18/153000) \[Jun 2023]
*   [LLM の推論を効率化する量子化技術調査](https://blog.brainpad.co.jp/entry/2023/09/01/153003): Survey of quantization techniques to improve efficiency of LLM reasoning \[Sep 2023]
*   [LLM の出力制御や新モデルについて](https://blog.brainpad.co.jp/entry/2023/09/08/155352): About LLM output control and new models \[Sep 2023]
*   [Azure OpenAI を活用したアプリケーション実装のリファレンス (⭐264)](https://github.com/Azure-Samples/jp-azureopenai-samples): 日本マイクロソフト リファレンスアーキテクチャ \[Jun 2023]
*   [生成 AI・LLM のツール拡張に関する論文の動向調査](https://blog.brainpad.co.jp/entry/2023/09/22/150341): Survey of trends in papers on tool extensions for generative AI and LLM \[Sep 2023]
*   [LLM の学習・推論の効率化・高速化に関する技術調査](https://blog.brainpad.co.jp/entry/2023/09/28/170010): Technical survey on improving the efficiency and speed of LLM learning and inference \[Sep 2023]

### **Learning and Supplementary Materials** / Korean

*   [gpt4free (⭐60k)](https://github.com/xtekky/gpt4free) for educational purposes only \[Mar 2023]
*   [IbrahimSobh/llms (⭐266)](https://github.com/IbrahimSobh/llms): Language models introduction with simple code. \[Jun 2023]
*   [DeepLearning.ai Short courses](https://www.deeplearning.ai/short-courses/): DeepLearning.ai Short courses \[2023]
*   [Deep Learning cheatsheets for Stanford's CS 230 (⭐6.3k)](https://github.com/afshinea/stanford-cs-230-deep-learning/tree/master/en): Super VIP Cheetsheet: Deep Learning \[Nov 2019]
*   [Best-of Machine Learning with Python (⭐16k)](https://github.com/ml-tooling/best-of-ml-python):🏆A ranked list of awesome machine learning Python libraries. \[Nov 2020]

### **Section 10: General AI Tools and Extensions** / **OSS Alternatives for OpenAI Code Interpreter (aka. Advanced Data Analytics)**

*   [Vercel AI](https://sdk.vercel.ai/) Vercel AI Playground / Vercel AI SDK [git (⭐9.1k)](https://github.com/vercel/ai) \[May 2023]
*   [Quora Poe](https://poe.com/login) A chatbot service that gives access to GPT-4, gpt-3.5-turbo, Claude from Anthropic, and a variety of other bots. \[Feb 2023]

### **Section 11: Datasets for LLM Training** / **OSS Alternatives for OpenAI Code Interpreter (aka. Advanced Data Analytics)**

*   [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/): The Stanford Question Answering Dataset (SQuAD), a set of Wikipedia articles, 100,000+ question-answer pairs on 500+ articles. \[16 Jun 2016]
*   [大規模言語モデルのデータセットまとめ](https://note.com/npaka/n/n686d987adfb1): 大規模言語モデルのデータセットまとめ \[Apr 2023]

## [2. Static Analysis](/content/analysis-tools-dev/static-analysis/README.md)

### Programming Languages / [Other](#other-1)

*   [JET (⭐726)](https://github.com/aviatesk/JET.jl) — Static type inference system to detect bugs and type instabilities.

---

- Prev: [Dec 15, 2023](/content/2023/12/15/README.md)
- Next: [Dec 13, 2023](/content/2023/12/13/README.md)